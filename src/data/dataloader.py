from typing import Optional, Tuple

import pandas as pd
import torch
from pathlib import Path
from torchvision.transforms import InterpolationMode
from torch.utils.data import DataLoader, Dataset

from src.data.dataset import Subset
from src.preprocessing.augmentation import get_transforms
from torchvision import transforms

def create_train_val_dataloaders(
    csv_path: Optional[str] = None,
    img_dir_path: Optional[str] = None,
    train_transform: Optional[transforms.Compose] = None,
    val_transform: Optional[transforms.Compose] = None,
    fraction: float = 1.0,
    train_ratio: float = 0.9,
    batch_size: int = 64,
    seed: int = 42,
    num_workers: int = 3,
    pin_memory: bool = False,
    dataset: Dataset = None,
) -> Tuple[DataLoader, DataLoader]:
    """
    –°–æ–∑–¥–∞—ë—Ç DataLoader'—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏,
    –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–æ–ª–∏ –¥–∞–Ω–Ω—ã—Ö, –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º.

    Args:
        csv_path: –ü—É—Ç—å –∫ CSV —Å –º–µ—Ç–∫–∞–º–∏. –ï—Å–ª–∏ None ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç.
        img_dir_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
        train_transform: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è train (augmentations). –ï—Å–ª–∏ None ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç.
        val_transform: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è val (–±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π). –ï—Å–ª–∏ None ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç.
        fraction: –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0.1 –¥–ª—è 10%).
        train_ratio: –î–æ–ª—è train –≤ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ (–æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî val).
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞.
        seed: Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏.
        num_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
        pin_memory: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ pinned memory (—É—Å–∫–æ—Ä—è–µ—Ç –ø–µ—Ä–µ–¥–∞—á—É –Ω–∞ GPU).

    Returns:
        –ö–æ—Ä—Ç–µ–∂ (train_loader, val_loader)

    Raises:
        FileNotFoundError: –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω CSV –∏–ª–∏ –ø–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
        ValueError: –ü—Ä–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö.
    """
    # --- –í–∞–ª–∏–¥–∞—Ü–∏—è –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ ---
    if not 0.0 < fraction <= 1.0:
        raise ValueError(f"fraction must be in (0, 1], got {fraction}")
    if not 0.0 < train_ratio < 1.0:
        raise ValueError(f"train_ratio must be in (0, 1), got {train_ratio}")
    if batch_size <= 0:
        raise ValueError(f"batch_size must be positive, got {batch_size}")
    # print(csv_path)
    if not csv_path:
        raise FileNotFoundError(f"CSV file not found: {csv_path}")

    train_transform, val_transform = get_transforms()

    # üí° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω —Ä–∞–∑ —á—Ç–µ–Ω–∏–µ CSV, –∫—ç—à–∏—Ä—É–µ–º –º–µ—Ç–∫–∏
    df = pd.read_csv(csv_path)

    total_size = len(df)

    subset_size = int(fraction * total_size)

    if subset_size == 0:
        raise ValueError("Fraction is too small, subset_size = 0")

    # --- üîÅ –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ ---
    generator = torch.Generator().manual_seed(seed)
    indices = torch.randperm(total_size, generator=generator).tolist()
    subset_indices = indices[:subset_size]

    train_split = int(train_ratio * len(subset_indices))
    train_indices = subset_indices[:train_split]
    val_indices = subset_indices[train_split:]

    if len(train_indices) == 0:
        raise ValueError("Train split is empty after applying fraction and ratio.")
    if len(val_indices) == 0:
        raise ValueError("Validation split is empty after applying fraction and ratio.")

    # --- üì¶ –î–≤–∞ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏ ---
    # –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ: –æ–Ω–∏ –¥–µ–ª—è—Ç –¥–∞–Ω–Ω—ã–µ (–µ—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –≥—Ä—É–∑–∏—Ç –≤—Å—ë –≤ –ø–∞–º—è—Ç—å —Å—Ä–∞–∑—É)
    train_dataset = dataset(csv_path=str(csv_path), total_path=img_dir_path, transform=train_transform)
    val_dataset = dataset(csv_path=str(csv_path), total_path=img_dir_path, transform=val_transform)

    train_subset = Subset(train_dataset, train_indices)
    val_subset = Subset(val_dataset, val_indices)

    # --- üöö DataLoader ---
    train_loader = DataLoader(
        train_subset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=True if num_workers > 0 else False,
        generator=generator,
    )

    val_loader = DataLoader(
        val_subset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=True if num_workers > 0 else False,
        generator=generator,
    )

    print(f"‚úÖ DataLoader created:")
    print(f"   Total dataset size: {total_size}")
    print(f"   Used fraction: {fraction:.1%} ‚Üí {subset_size} samples")
    print(f"   Train: {len(train_indices)} | Val: {len(val_indices)}")
    print(f"   Batch size: {batch_size}, Workers: {num_workers}")

    return train_loader, val_loader