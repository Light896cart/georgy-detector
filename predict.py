import os
import torch
from PIL import Image
import requests
from io import BytesIO
from torchvision import transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from pathlib import Path
from typing import List, Tuple, Union

from src.model.model_architecture import create_model

# --- –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ ---
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# --- –ö–ª–∞—Å—Å—ã ---
CLASS_NAMES = {0: "–≠—Ç–æ –ì–µ–æ—Ä–≥–∏–π –ü–æ–±–µ–¥–æ–Ω–æ—Å–µ—Ü", 1: "–ù–µ –ì–µ–æ—Ä–≥–∏–π –ü–æ–±–µ–¥–æ–Ω–æ—Å–µ—Ü"}

def load_model(weights_path: str = 'best_model.pth', device: str = None) -> torch.nn.Module:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å.
    –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å ‚Äî —ç—Ç–æ ResNet-18 —Å SE-–±–ª–æ–∫–∞–º–∏.
    """
    if not os.path.exists(weights_path):
        raise FileNotFoundError(f"–§–∞–π–ª –≤–µ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {weights_path}. "
                                f"–û–∂–∏–¥–∞–µ—Ç—Å—è: {os.path.abspath(weights_path)}")
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"

    model = create_model(pretrained=False, freeze_backbone=False)  # –∫–∞–∫ –≤ train.py
    model.to(device)
    model.eval()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
    checkpoint = torch.load(weights_path, map_location=device)
    if 'state_dict' in checkpoint:
        model.load_state_dict(checkpoint['state_dict'])
    else:
        model.load_state_dict(checkpoint)

    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑: {weights_path}")
    return model

def load_image(image_source: Union[str, Path]) -> Image.Image:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:
    - –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å http ‚Üí –≥—Ä—É–∑–∏—Ç —Å URL
    - –∏–Ω–∞—á–µ ‚Üí —Å—á–∏—Ç–∞–µ—Ç –ø—É—Ç—ë–º –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    if isinstance(image_source, (Path, str)) and str(image_source).startswith(('http://', 'https://')):
        response = requests.get(str(image_source), timeout=10)
        response.raise_for_status()
        image = Image.open(BytesIO(response.content)).convert("RGB")
    else:
        image_path = Path(image_source)
        if not image_path.exists():
            raise FileNotFoundError(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {image_path}")
        image = Image.open(image_path).convert("RGB")
    return image

def predict_image(model: torch.nn.Module, image_source: Union[str, Path], device: str = None) -> Tuple[str, float]:
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –æ–±—Ä–∞–∑.
    Args:
        model: –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        image_source: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ URL
        device: 'cpu' –∏–ª–∏ 'cuda'

    Returns:
        (–∫–ª–∞—Å—Å, –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)
    """
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"

    try:
        image = load_image(image_source)
        input_tensor = transform(image).unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(input_tensor)
            probs = torch.nn.functional.softmax(output, dim=1)
            confidence, pred = torch.max(probs, 1)
            class_idx = pred.item()
            conf = confidence.item()

        class_name = CLASS_NAMES[class_idx]
        return class_name, conf

    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {str(e)}", 0.0

def predict_from_folder(model: torch.nn.Module, folder_path: str, device: str = None):
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –¥–ª—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–ø–∫–µ.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: .jpg, .jpeg, .png, .bmp, .tiff
    """
    folder = Path(folder_path)
    if not folder.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder}")
        return

    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')
    image_files = [f for f in folder.iterdir() if f.suffix.lower() in image_extensions]

    if not image_files:
        print(f"‚ùå –ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–ø–∫–µ: {folder}")
        return

    print(f"\nüîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –ø–∞–ø–∫–∏: {folder}")
    results = []

    for img_path in image_files:
        class_name, conf = predict_image(model, img_path, device)
        results.append((img_path.name, class_name, conf))
        print(f"üñºÔ∏è  {img_path.name:30} ‚Üí {class_name} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {conf:.4f})")

    return results

def visualize_predictions(image_source: Union[str, Path], prediction: str, confidence: float):
    """
    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.
    """
    try:
        image = load_image(image_source)
        plt.figure(figsize=(6, 6))
        plt.imshow(image)
        plt.title(f"{prediction}\n(–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {confidence:.4f})", fontsize=14, color='green' if "–ì–µ–æ—Ä–≥–∏–π" in prediction else 'red')
        plt.axis("off")
        plt.tight_layout()
        plt.show()
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å: {e}")


# --- CLI ‚Äî –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –∫–∞–∫ —Å–∫—Ä–∏–ø—Ç ---
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="üîç –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏: –ì–µ–æ—Ä–≥–∏–π –ü–æ–±–µ–¥–æ–Ω–æ—Å–µ—Ü –∏–ª–∏ –Ω–µ—Ç",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python predict.py --weights best_model.pth --image test.jpg
  python predict.py --weights best_model.pth --image "https://example.com/georgy.jpg"
  python predict.py --weights best_model.pth --folder ./images/
  python predict.py --weights best_model.pth  # ‚Üê –ø–æ–ø—Ä–æ—Å–∏—Ç –≤—ã–±—Ä–∞—Ç—å image –∏–ª–∏ folder
        """
    )
    parser.add_argument(
        "--weights",
        type=str,
        default="best_model.pth",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–µ—Å–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: best_model.pth)"
    )
    parser.add_argument(
        "--image",
        type=str,
        help="–ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏–ª–∏ URL"
    )
    parser.add_argument(
        "--folder",
        type=str,
        help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏"
    )
    parser.add_argument(
        "--device",
        type=str,
        default=None,
        choices=["cpu", "cuda"],
        help="–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: auto)"
    )

    args = parser.parse_args()

    # --- üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Å–æ–≤ ---
    if not os.path.exists(args.weights):
        print(f"‚ùå –§–∞–π–ª —Å –≤–µ—Å–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.weights}")
        print(f"üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –ª–µ–∂–∏—Ç –≤: {os.path.abspath(args.weights)}")
        exit(1)

    # --- üîç –ü—Ä–æ–≤–µ—Ä–∫–∞: —á—Ç–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å ---
    if not args.image and not args.folder:
        print("ü§î –ù–µ —É–∫–∞–∑–∞–Ω–æ, —á—Ç–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å.")
        print("üëâ –£–∫–∞–∂–∏—Ç–µ –æ–¥–Ω–æ –∏–∑:")
        print("   --image <–ø—É—Ç—å_–∏–ª–∏_URL>    ‚Üí –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        print("   --folder <–ø–∞–ø–∫–∞>          ‚Üí –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        print("\n–ü—Ä–∏–º–µ—Ä—ã:")
        print("   python predict.py --weights best_model.pth --image test.jpg")
        print("   python predict.py --weights best_model.pth --folder ./images/")
        print("\n–ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --help –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏.")
        exit(1)

    # --- ‚úÖ –í—Å—ë –æ–∫ ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º ---
    device = args.device or ("cuda" if torch.cuda.is_available() else "cpu")
    model = load_model(args.weights, device)

    if args.image:
        pred, conf = predict_image(model, args.image, device)
        print(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç: {pred} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {conf:.4f})")
        visualize_predictions(args.image, pred, conf)

    if args.folder:
        predict_from_folder(model, args.folder, device)